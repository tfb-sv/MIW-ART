{
"bbbp2k":
    {
    "task": ["clf"],
    "optimizer": ["adadelta"],
    "dropout": [0.3],
    "clf_num_layers": [5],
    "DTA_hidden_dim": [6144], 
    "lr": [1e-3],
    "tree_hidden_dim": [300],
    "use_batchnorm": [1],
    "rank_input": ["h"],
    "max_epoch": [400]
    },
"bace":
    {
    "task": ["clf"],
    "optimizer": ["adadelta"],
    "dropout": [0.3],
    "clf_num_layers": [1],
    "DTA_hidden_dim": [6144], 
    "lr": [1e-3],
    "tree_hidden_dim": [300],
    "use_batchnorm": [1],
    "rank_input": ["h"],
    "max_epoch": [100]
    },
"tox21":
    {
    "task": ["clf"],
    "optimizer": ["adadelta"],
    "dropout": [0.5],
    "clf_num_layers": [5],
    "DTA_hidden_dim": [2048], 
    "lr": [1e-3],
    "tree_hidden_dim": [1500],
    "use_batchnorm": [0],
    "rank_input": ["w"],
    "max_epoch": [100]
    },
"clintox":
    {
    "task": ["clf"],
    "optimizer": ["adadelta"],
    "dropout": [0.5],
    "clf_num_layers": [3],
    "DTA_hidden_dim": [2048], 
    "lr": [1e-3],
    "tree_hidden_dim": [100],
    "use_batchnorm": [1],
    "rank_input": ["h"],
    "max_epoch": [400]
    },
"bbbp8k":
    {
    "task": ["clf"],
    "optimizer": ["adadelta"],
    "dropout": [0.5],
    "clf_num_layers": [3],
    "DTA_hidden_dim": [3072], 
    "lr": [1e-3, 1e-4, 1e-5],
    "tree_hidden_dim": [50, 100, 200, 300, 500, 1000, 1500],
    "use_batchnorm": [1, 0],
    "rank_input": ["w", "h"],
    "max_epoch": [40]
    },
"lipo":
    {
    "task": ["reg"],
    "optimizer": ["adam"],
    "dropout": [0.3, 0.5],
    "clf_num_layers": [1],
    "DTA_hidden_dim": [512, 3072], 
    "lr": [1e-3],
    "tree_hidden_dim": [300, 500],
    "use_batchnorm": [1],
    "rank_input": ["h"],
    "max_epoch": [100]
    },
"esol":
    {
    "task": ["reg"],
    "optimizer": ["adagrad"],
    "dropout": [0.3, 0.7],
    "clf_num_layers": [1, 3],
    "DTA_hidden_dim": [8, 64, 128], 
    "lr": [1e-3],
    "tree_hidden_dim": [50],
    "use_batchnorm": [0],
    "rank_input": ["h"],
    "max_epoch": [150]
    },
"example":
    {
    "task": ["clf"],
    "optimizer": ["adadelta", "adam", "adagrad"],
    "dropout": [0.1, 0.3, 0.5, 0.7, 0.8, 0.9],
    "clf_num_layers": [1, 2, 3, 5, 7, 10],
    "DTA_hidden_dim": [8, 16, 32, 64, 128, 256, 512, 1024, 2048, 3072, 4096], 
    "lr": [1e-3, 1e-4, 1e-5],
    "tree_hidden_dim": [50, 100, 200, 300, 500, 1000, 1500],
    "use_batchnorm": [1, 0],
    "rank_input": ["w", "h"],
    "max_epoch": [100]
    }
}